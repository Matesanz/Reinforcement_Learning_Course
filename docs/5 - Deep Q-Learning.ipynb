{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22a6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Avoid TF Debug Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5982e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821f3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9289702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = gym.make(\"FrozenLake-v1\", is_slippery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5abaee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b3b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b8ebd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size: int, hidden_size: int, output_size: int, optimizer: Union[Adam, SGD]) -> Model:\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_size, name=\"input\"))\n",
    "    model.add(Dense(hidden_size, activation='relu',name=\"hidden_1\"))\n",
    "    model.add(Dense(hidden_size, activation='relu',name=\"hidden_2\"))\n",
    "    model.add(Dense(output_size, activation=\"linear\", name=\"output\"))\n",
    "    model.compile(loss=MeanSquaredError(), optimizer=optimizer, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "472b5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Memory:\n",
    "    prev_obs: int\n",
    "    action: int\n",
    "    actual_obs: int\n",
    "    reward: float\n",
    "    done: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d64beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, environment: Env):\n",
    "        \n",
    "        self.env = environment\n",
    "        action_space = self.env.action_space.n\n",
    "        self.observation_space = self.env.observation_space.n\n",
    "        self.epsilon = 0.9\n",
    "        self.epsilon_min = 0.1\n",
    "        self.gamma = 0.9\n",
    "        optimizer = Adam()\n",
    "        self.q_learning_nn = build_model(input_size=self.observation_space, hidden_size=64, output_size=action_space, optimizer=optimizer)\n",
    "        self.target_nn = build_model(input_size=self.observation_space, hidden_size=64, output_size=action_space, optimizer=optimizer)\n",
    "        self.transfer_learning()\n",
    "        self.memory = deque(maxlen=2000)\n",
    "    \n",
    "    def transfer_learning(self) -> None:\n",
    "        \n",
    "        self.target_nn.set_weights(self.q_learning_nn.get_weights())\n",
    "    \n",
    "    def _get_random_action(self) -> int:\n",
    "        \n",
    "        return self.env.action_space.sample()\n",
    "    \n",
    "    def _get_best_action(self, observation: np.ndarray) -> int:\n",
    "        observation = self.one_hot_obs_encoding(observation)\n",
    "        q_values = self.q_learning_nn.predict(observation)\n",
    "        return np.argmax(q_values)\n",
    "    \n",
    "    def get_action(self, obs: int) -> int:\n",
    "        \n",
    "        if self.epsilon > random.random():\n",
    "            action = self._get_random_action()\n",
    "        else:\n",
    "            action = self._get_best_action(obs)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        return self.env.step(action=action)\n",
    "    \n",
    "    def memorize(self, memory: Memory) -> None:\n",
    "        \n",
    "        self.memory.append(memory)\n",
    "        \n",
    "    def one_hot_obs_encoding(self, obs: int):\n",
    "        \n",
    "        return one_hot([obs], self.observation_space)\n",
    "    \n",
    "        \n",
    "    def get_batch_sample(self, batch_size:int) -> List[Memory]:\n",
    "        \n",
    "        return np.random.choice(self.memory, size=batch_size)\n",
    "    \n",
    "    def learn(self, batch: List[Memory]) -> None:\n",
    "        \n",
    "        for mem in batch:\n",
    "            \n",
    "            prev_obs = self.one_hot_obs_encoding(mem.prev_obs)\n",
    "            target = self.q_learning_nn.predict(prev_obs)\n",
    "\n",
    "            if mem.done:\n",
    "                action_target = mem.reward\n",
    "            else:\n",
    "                actual_obs = self.one_hot_obs_encoding(mem.actual_obs)\n",
    "                Q_actions = self.target_nn.predict(actual_obs)  # Array with the value of every action\n",
    "                best_Q = np.max(Q_actions)  # highest Q (value of action)\n",
    "                action_target = mem.reward + self.gamma * best_Q\n",
    "\n",
    "            target[0][action] = action_target\n",
    "            self.q_learning_nn.fit(prev_obs, target, epochs=1, verbose=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe8cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c88a2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "EPISODES = 30\n",
    "BATCH_SIZE = 128\n",
    "EPSILON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25af44d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENV.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e56f846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36f706d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "testing...\n",
      "Episodios ejecutados con éxito: 0/20\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "testing...\n",
      "Episodios ejecutados con éxito: 0/20\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    # Reducción de epsilon tras cada época\n",
    "    if EPSILON > EPSILON_MIN:\n",
    "        EPSILON -= (EPSILON*EPSILON_DECAY)\n",
    "    \n",
    "    \n",
    "    for episode in range(EPISODES):\n",
    "        \n",
    "        obs = a.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = a.get_action(obs)\n",
    "            next_obs, reward, done, _ = a.step(action)\n",
    "            memory = Memory(prev_obs=obs, action=action, reward=reward, actual_obs=next_obs, done=done)\n",
    "            a.memorize(memory)\n",
    "            obs = next_obs\n",
    "\n",
    "    if len(a.memory) > BATCH_SIZE:\n",
    "\n",
    "        memories_batch = a.get_batch_sample(BATCH_SIZE)\n",
    "        a.learn(memories_batch)\n",
    "    \n",
    "    a.transfer_learning()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"testing...\")\n",
    "        winning_eps = 0\n",
    "        for i in range(20):\n",
    "            obs = a.env.reset()\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                action = a._get_best_action(obs)\n",
    "                obs, reward, done, _ = a.step(action)\n",
    "\n",
    "            if reward > 0:\n",
    "                winning_eps += 1\n",
    "        print(f\"Episodios ejecutados con éxito: {winning_eps}/{20}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c881ad94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cSDFADS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_220717/1556639069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcSDFADS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cSDFADS' is not defined"
     ]
    }
   ],
   "source": [
    "cSDFADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "a._get_best_action(np.array([14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0902626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00028756  0.0711957   0.09674872  0.01330076]]\n",
      "[[-0.00308418  0.17789477  0.02960289  0.0144994 ]]\n",
      "[[ 0.05342163  0.06541891  0.09196578 -0.04542448]]\n",
      "[[-0.0414832   0.08320257  0.07246859  0.05209388]]\n",
      "[[0.06490675 0.09544932 0.08541021 0.02386591]]\n",
      "[[-0.06740799 -0.02699154 -0.00328358  0.03000134]]\n",
      "[[-0.0626333   0.0495147   0.03806045  0.05013835]]\n",
      "[[-0.02179249  0.1723306   0.20717674  0.09099585]]\n",
      "[[-0.01864198 -0.05439937  0.14734642  0.01183955]]\n",
      "[[0.02369849 0.03977751 0.05222321 0.15109932]]\n",
      "[[-0.00705086 -0.0755577  -0.02279143 -0.02170666]]\n",
      "[[ 0.07660863 -0.04861972  0.06283103  0.07374804]]\n",
      "[[-0.02295548  0.10677442  0.2486935   0.13104504]]\n",
      "[[0.02356146 0.0693612  0.07705854 0.16463512]]\n",
      "[[ 0.02332428  0.1136844   0.22718623 -0.01120121]]\n",
      "[[-0.01612626  0.11861486  0.18312223  0.11506802]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    act = a.one_hot_obs_encoding(i)\n",
    "    print(a.q_learning_nn.predict(act))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb0328",
   "metadata": {},
   "source": [
    "### Gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Memory:\n",
    "    prev_obs: int\n",
    "    action: int\n",
    "    actual_obs: int\n",
    "    reward: float\n",
    "    done: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c68406",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 1000\n",
    "memory_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7539db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(EPISODES):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        \n",
    "        # Select Action\n",
    "        action = env.action_space.sample() # Random action: Exploration\n",
    "\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Save into memory\n",
    "        mem = Memory(\n",
    "            prev_obs = obs,\n",
    "            action = action,\n",
    "            actual_obs = next_obs,\n",
    "            reward = reward,\n",
    "            done = done\n",
    "        )\n",
    "        \n",
    "        memory_list.append(mem)\n",
    "        \n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076a3c2",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=1, name=\"input\"))\n",
    "model.add(Dense(16, activation='relu',name=\"hidden0\"))\n",
    "model.add(Dense(16, activation='relu',name=\"hidden1\"))\n",
    "model.add(Dense(16, activation='relu',name=\"hidden2\"))\n",
    "model.add(Dense(16, activation='relu',name=\"hidden3\"))\n",
    "model.add(Dense(4, activation=\"sigmoid\", name=\"output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fb84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07088fff",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bab264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62075464",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf98402",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_obs_arr = np.array([mem.prev_obs for mem in memory_list])\n",
    "next_obs_arr = np.array([mem.actual_obs for mem in memory_list])\n",
    "done_arr = np.array([mem.done for mem in memory_list])\n",
    "reward_arr = np.array([mem.reward for mem in memory_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ab4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_obs_Q = model.predict(prev_obs_arr)\n",
    "next_obs_Q = model.predict(next_obs_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bafaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = prev_obs_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df934ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df810c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "memory_sample = random.sample(memory_list, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655667fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(memory_sample: List[Memory], model: Model):\n",
    "    for mem in memory_sample:\n",
    "    \n",
    "        prev_obs = np.array([mem.prev_obs])\n",
    "        target = model.predict(prev_obs)\n",
    "\n",
    "        if mem.done:\n",
    "            action_target = mem.reward\n",
    "        else:\n",
    "            Q_actions = model.predict([mem.actual_obs])  # Array with the value of every action\n",
    "            best_Q = np.max(Q_actions)  # highest Q (value of action)\n",
    "            action_target = mem.reward + gamma * best_Q\n",
    "\n",
    "        target[0][action] = action_target\n",
    "        model.fit(prev_obs, target, epochs=1, verbose=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88244e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4270602",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array([14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db57d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e002da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(Q_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d487c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
