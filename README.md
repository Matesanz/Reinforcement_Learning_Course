# ğŸ‘‹ Curso sobre Reinforcement Learning

## ğŸ™‚ DescripciÃ³n

En este curso se incluye **todo lo bÃ¡sico relacionado con el Aprendizaje por Refuerzo**. Desde los conceptos mÃ¡s bÃ¡sicos, como quÃ© es una cadena de Markov, hasta conceptos mÃ¡s interesantes como la **inclusiÃ³n de Redes Neuronales** en algoritmos de RL. Para ello, cada una de las clases cuenta con un Jupyter Notebook ejecutable con toda la teorÃ­a y con imÃ¡genes de esquemas que ayudan a una mejor comprensiÃ³n. Esta pensado para que sea un **curso desde 0**, por ello, tanto si eres principiante, como si quieres refrescar conocimientos, este curso es para ti.

## ğŸ”– Tabla de Contenidos

- [ğŸ‘‹ Curso sobre Reinforcement Learning](#-curso-sobre-reinforcement-learning)
  - [ğŸ™‚ DescripciÃ³n](#-descripciÃ³n)
  - [ğŸ”– Tabla de Contenidos](#-tabla-de-contenidos)
- [ğŸ“œ Temas](#-temas)
  - [0ï¸âƒ£ IntroducciÃ³n a Reinforcement Learning](#0ï¸âƒ£-introducciÃ³n-a-reinforcement-learning)
  - [1ï¸âƒ£ IntroducciÃ³n a Reinforcement Learning ğŸ—ï¸ (En construcciÃ³n...)](#1ï¸âƒ£-introducciÃ³n-a-reinforcement-learning-ï¸-en-construcciÃ³n)
  - [2ï¸âƒ£ EcuaciÃ³n de Bellman y Q-Learning ğŸ—ï¸ (En construcciÃ³n...)](#2ï¸âƒ£-ecuaciÃ³n-de-bellman-y-q-learning-ï¸-en-construcciÃ³n)
  - [3ï¸âƒ£ Deep Reinforcement Learning ğŸ—ï¸ (En construcciÃ³n...)](#3ï¸âƒ£-deep-reinforcement-learning-ï¸-en-construcciÃ³n)
- [âš¡ Quick-Start: usando remote containers](#-quick-start-usando-remote-containers)

Este curso estÃ¡ dividido en varias partes:

# ğŸ“œ Temas

Para ejecutar los notebooks la mejor forma es [usar docker](#-quick-start-usando-remote-containers). En apenas **unos minutos y sin instalar nada** tendrÃ¡s acceso a todos los notebooks. ğŸ¤¯

## 0ï¸âƒ£ IntroducciÃ³n a Reinforcement Learning
- Agente y Entorno
- Recompensas, Observaciones y Acciones
- Equilibrio ExploraciÃ³n ExplotaciÃ³n
- Maximizar la Recompensa a largo plazo
- Descubriendo Gym: Creando mi primer entorno
- Descubriendo Gym: Creando mi primer agente
  
![Reinforcement Learning Intro](https://user-images.githubusercontent.com/44867923/139915800-8224bede-c52b-47d1-bb22-2e9624687831.jpg)

## 1ï¸âƒ£ EcuaciÃ³n de Bellman: El valor de los estados
- V-table: asignando un valor a cada estado
- EcuaciÃ³n de Bellman: calculando V para cada estado
- CÃ¡lculo de la PolÃ­tica usando la V-table


![Bellman_equation State_Value](https://user-images.githubusercontent.com/44867923/140994794-51d739af-eb70-4e6a-9036-b925f23ab7fd.jpg)

## 2ï¸âƒ£ EcuaciÃ³n de Bellman: El valor de las acciones
- Las acciones en los Procesos de decisiÃ³n de Markov
- Q: El valor de las acciones
- ProgramaciÃ³n DinÃ¡mica: IteraciÃ³n de Valores

![Q-value](https://user-images.githubusercontent.com/44867923/141012134-09ff0d88-4ce9-43af-8b04-d535cf24d897.jpg)

## 3ï¸âƒ£ Q Learning
- Diferencias Temporales: Q-learning
- Alpha: aprender mÃ¡s de lo nuevo o de lo viejo
- Gamma: cuanto mÃ¡s lejos en el futuro menos confianza
- La polÃ­tica Ã“ptima

![Q-learning](https://user-images.githubusercontent.com/44867923/141012234-257d26af-bf05-4dad-b402-96b54c735f41.jpg)


# âš¡ Quick-Start: usando remote containers

**1. Instala el Plugin de VSCode de [Remote Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)**

```
# Presiona Ctrl + shift + p
# Pega ext install ms-vscode-remote.remote-containers
# Presiona Enter
```

**2. Abre el entorno de desarrollo**

```
# Presiona Ctrl + shift + p
# Busca: Remote-Containers: Rebuild and Reopen in container
# Presiona Enter (y espera, la primera vez tarda unos minutos)
```

**3. Abre los Notebooks**

Abre el buscador y ve a [http://127.0.0.1:8888/](http://127.0.0.1:8888/)
