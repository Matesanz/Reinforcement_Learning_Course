# üëã Curso sobre Reinforcement Learning

## üôÇ Descripci√≥n

En este curso se incluye **todo lo b√°sico relacionado con el Aprendizaje por Refuerzo**. Desde los conceptos m√°s b√°sicos, como qu√© es una cadena de Markov, hasta conceptos m√°s interesantes como la **inclusi√≥n de Redes Neuronales** en algoritmos de RL. Para ello, cada una de las clases cuenta con un Jupyter Notebook ejecutable con toda la teor√≠a y con im√°genes de esquemas que ayudan a una mejor comprensi√≥n. Esta pensado para que sea un **curso desde 0**, por ello, tanto si eres principiante, como si quieres refrescar conocimientos, este curso es para ti.

## üîñ Tabla de Contenidos

- [üëã Curso sobre Reinforcement Learning](#-curso-sobre-reinforcement-learning)
  - [üôÇ Descripci√≥n](#-descripci√≥n)
  - [üîñ Tabla de Contenidos](#-tabla-de-contenidos)
- [üìú Temas](#-temas)
  - [0Ô∏è‚É£ Introducci√≥n a Reinforcement Learning](#0Ô∏è‚É£-introducci√≥n-a-reinforcement-learning)
  - [1Ô∏è‚É£ Ecuaci√≥n de Bellman: El valor de los estados](#1Ô∏è‚É£-ecuaci√≥n-de-bellman-el-valor-de-los-estados)
  - [2Ô∏è‚É£ Ecuaci√≥n de Bellman: El valor de las acciones](#2Ô∏è‚É£-ecuaci√≥n-de-bellman-el-valor-de-las-acciones)
  - [3Ô∏è‚É£ Q Learning](#3Ô∏è‚É£-q-learning)
- [‚ö° Quick-Start: usando remote containers](#-quick-start-usando-remote-containers)

Este curso est√° dividido en varias partes:

# üìú Temas

Para ejecutar los notebooks la mejor forma es [usar docker](#-quick-start-usando-remote-containers). En apenas **unos minutos y sin instalar nada** tendr√°s acceso a todos los notebooks. ü§Ø

## 0Ô∏è‚É£ Introducci√≥n a Reinforcement Learning
- Agente y Entorno
- Recompensas, Observaciones y Acciones
- Equilibrio Exploraci√≥n Explotaci√≥n
- Maximizar la Recompensa a largo plazo
- Descubriendo Gym: Creando mi primer entorno
- Descubriendo Gym: Creando mi primer agente
  
![Reinforcement Learning Intro](https://user-images.githubusercontent.com/44867923/139915800-8224bede-c52b-47d1-bb22-2e9624687831.jpg)

## 1Ô∏è‚É£ Ecuaci√≥n de Bellman: El valor de los estados
- V-table: asignando un valor a cada estado
- Ecuaci√≥n de Bellman: calculando V para cada estado
- C√°lculo de la Pol√≠tica usando la V-table


![Bellman_equation State_Value](https://user-images.githubusercontent.com/44867923/140994794-51d739af-eb70-4e6a-9036-b925f23ab7fd.jpg)

## 2Ô∏è‚É£ Ecuaci√≥n de Bellman: El valor de las acciones
- Las acciones en los Procesos de decisi√≥n de Markov
- Q: El valor de las acciones
- Programaci√≥n Din√°mica: Iteraci√≥n de Valores

![Q-value](https://user-images.githubusercontent.com/44867923/141012134-09ff0d88-4ce9-43af-8b04-d535cf24d897.jpg)

## 3Ô∏è‚É£ Q Learning
- Diferencias Temporales: Q-learning
- Alpha: aprender m√°s de lo nuevo o de lo viejo
- Gamma: cuanto m√°s lejos en el futuro menos confianza
- La pol√≠tica √ìptima

![Q-learning](https://user-images.githubusercontent.com/44867923/141012234-257d26af-bf05-4dad-b402-96b54c735f41.jpg)


# ‚ö° Quick-Start: usando remote containers

**1. Instala el Plugin de VSCode de [Remote Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)**

```
# Presiona Ctrl + shift + p
# Pega ext install ms-vscode-remote.remote-containers
# Presiona Enter
```

**2. Abre el entorno de desarrollo**

```
# Presiona Ctrl + shift + p
# Busca: Remote-Containers: Rebuild and Reopen in container
# Presiona Enter (y espera, la primera vez tarda unos minutos)
```

**3. Abre los Notebooks**

Abre el buscador y ve a [http://127.0.0.1:8888/](http://127.0.0.1:8888/)
